{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dbdf3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da38d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Florence2ForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoProcessor\n",
    "\n",
    "model = AutoModel.from_pretrained(\"2toINF/X-VLA-SoftFold\", trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(\"2toINF/X-VLA-SoftFold\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfa87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import build_optimizer\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import TorchDynamoPlugin, DynamoBackend\n",
    "\n",
    "import torch\n",
    "torch._dynamo.config.capture_dynamic_output_shape_ops = True\n",
    "\n",
    "# Configure the compilation backend\n",
    "dynamo_plugin = TorchDynamoPlugin(\n",
    "    backend=DynamoBackend.INDUCTOR,\n",
    "    mode=\"max-autotune\",      # Options: \"default\", \"reduce-overhead\", \"max-autotune\"\n",
    "    fullgraph=True,\n",
    "    dynamic=False,\n",
    "    # options=...,\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    log_with=\"tensorboard\", \n",
    "    project_dir=\".xvla\",\n",
    "    # NOTE do not use torch.compile as Florence2 doesnt support it for training\n",
    "    # dynamo_plugin=dynamo_plugin,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86db8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = build_optimizer(\n",
    "    model=model,\n",
    "    lr=1e-2,\n",
    "    weight_decay=0.,\n",
    "    # betas=tuple(args.betas),\n",
    "    # lr_coef_soft=args.learning_coef,\n",
    ")\n",
    "model, optim = accelerator.prepare(model, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f1acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "model.forward(\n",
      "    input_ids: \u001b[33m'torch.LongTensor'\u001b[39m,\n",
      "    image_input: \u001b[33m'torch.FloatTensor'\u001b[39m,\n",
      "    image_mask: \u001b[33m'torch.Tensor'\u001b[39m,\n",
      "    domain_id: \u001b[33m'torch.LongTensor'\u001b[39m,\n",
      "    proprio: \u001b[33m'torch.Tensor'\u001b[39m,\n",
      "    action: \u001b[33m'torch.Tensor'\u001b[39m,\n",
      ") -> \u001b[33m'Dict[str, torch.Tensor]'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "1) Encode multimodal inputs.\n",
      "2) Diffusion-style noisy mixture of actions: x_t = t*noise + (1-t)*gt.\n",
      "3) Space-specific preprocessing, prediction, and supervised loss.\n",
      "\u001b[31mFile:\u001b[39m      ~/.cache/huggingface/modules/transformers_modules/2toINF/X-VLA-SoftFold/a67dc68f1264e97f8aeb06bc71384a41a3d6b0eb/modeling_xvla.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "model.forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da5f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56c646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "778702ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 4, 0],\n",
       "        [0, 0, 5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.asarray([\n",
    "    [1, 0, 0, 1],\n",
    "    [0, 4, 0, 2],\n",
    "    [0, 0, 5, 3],\n",
    "    [0, 0, 0, 1],\n",
    "])\n",
    "a[..., :3, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae19d992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41198225,  0.05872664,  0.90929743],\n",
       "       [-0.68124272, -0.64287284,  0.35017549],\n",
       "       [ 0.60512725, -0.76371834, -0.2248451 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.spatial.transform\n",
    "scipy.spatial.transform.Rotation.from_euler(\"XYZ\", [1, 2, 3]).as_matrix()[..., :, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "144a3a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scipy.spatial.transform' from '/home/ace/X-VLA/.conda/lib/python3.11/site-packages/scipy/spatial/transform/__init__.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.spatial.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acf058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05bd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bd460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:111: operator(): block: [0,0,0], thread: [0,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:111: operator(): block: [0,0,0], thread: [1,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m proprio = torch.full((\u001b[32m1\u001b[39m, \u001b[32m7\u001b[39m), fill_value=\u001b[32m0.\u001b[39m)\n\u001b[32m     16\u001b[39m action = torch.full((\u001b[32m1\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m20\u001b[39m), fill_value=\u001b[32m0.\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m losses = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_mask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdomain_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdomain_id\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproprio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproprio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43maction\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m total_loss = \u001b[38;5;28msum\u001b[39m(losses.values())\n\u001b[32m     27\u001b[39m accelerator.backward(total_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/2toINF/X-VLA-SoftFold/a67dc68f1264e97f8aeb06bc71384a41a3d6b0eb/modeling_xvla.py:164\u001b[39m, in \u001b[36mXVLA.forward\u001b[39m\u001b[34m(self, input_ids, image_input, image_mask, domain_id, proprio, action)\u001b[39m\n\u001b[32m    160\u001b[39m t = (torch.rand(\u001b[32m1\u001b[39m, device=input_ids.device)\n\u001b[32m    161\u001b[39m      + torch.arange(B, device=input_ids.device) / B) % (\u001b[32m1\u001b[39m - \u001b[32m1e-5\u001b[39m)\n\u001b[32m    163\u001b[39m action_noisy = torch.randn_like(action) * t.view(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m) + action * (\u001b[32m1\u001b[39m - t).view(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m proprio_m, action_noisy_m = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproprio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_noisy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m pred_action = \u001b[38;5;28mself\u001b[39m.transformer(\n\u001b[32m    167\u001b[39m     domain_id=domain_id,\n\u001b[32m    168\u001b[39m     action_with_noise=action_noisy_m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m     **enc,\n\u001b[32m    172\u001b[39m )\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.action_space.compute_loss(pred_action, action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/2toINF/X-VLA-SoftFold/a67dc68f1264e97f8aeb06bc71384a41a3d6b0eb/action_hub.py:161\u001b[39m, in \u001b[36mEE6DActionSpace.preprocess\u001b[39m\u001b[34m(self, proprio, action, mode)\u001b[39m\n\u001b[32m    159\u001b[39m action_m = action.clone()\n\u001b[32m    160\u001b[39m proprio_m[..., \u001b[38;5;28mself\u001b[39m.gripper_idx] = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[43maction_m\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgripper_idx\u001b[49m\u001b[43m]\u001b[49m = \u001b[32m0.0\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proprio_m, action_m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from train import update_group_lrs\n",
    "from datasets.domain_config import DATA_WEIGHTS, DATA_DOMAIN_ID\n",
    "\n",
    "max_grad_norm = 1.\n",
    "\n",
    "# TODO\n",
    "model.train(mode=True)\n",
    "\n",
    "input_ids = processor.encode_language(\"do something\")[\"input_ids\"]\n",
    "image_input = torch.full((1, 3, 3, 224, 224), fill_value=0.)\n",
    "image_mask = torch.full((1, 3), fill_value=True)\n",
    "domain_id = torch.full((1,), fill_value=DATA_DOMAIN_ID[\"lift2\"])\n",
    "proprio = torch.full((1, 20), fill_value=0.)\n",
    "action = torch.full((1, 30, 20), fill_value=0.)\n",
    "\n",
    "losses = model.forward(\n",
    "    input_ids=input_ids.to(model.device, non_blocking=True),\n",
    "    image_input=image_input.to(model.device, non_blocking=True),\n",
    "    image_mask=image_mask.to(model.device, non_blocking=True),\n",
    "    domain_id=domain_id.to(model.device, non_blocking=True),\n",
    "    proprio=proprio.to(model.device, non_blocking=True),\n",
    "    action=action.to(model.device, non_blocking=True),\n",
    ")\n",
    "total_loss = sum(losses.values())\n",
    "accelerator.backward(total_loss)\n",
    "\n",
    "if max_grad_norm is not None:\n",
    "    accelerator.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "# TODO\n",
    "update_group_lrs(\n",
    "    optim, \n",
    "    step=0, \n",
    "    args=SimpleNamespace(\n",
    "        # TODO\n",
    "        learning_rate=1e-4,\n",
    "        # TODO\n",
    "        learning_coef=1.,\n",
    "        # TODO\n",
    "        freeze_steps=1000,\n",
    "        warmup_steps=2000,\n",
    "        # TODO\n",
    "        iters=1000000,\n",
    "        min_lr_ratio=.1,\n",
    "        use_cosine_decay=False,\n",
    "    ),\n",
    ")\n",
    "optim.step()\n",
    "optim.zero_grad()\n",
    "\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c75c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mType:\u001b[39m        int\n",
      "\u001b[31mString form:\u001b[39m 30\n",
      "\u001b[31mDocstring:\u001b[39m  \n",
      "int([x]) -> integer\n",
      "int(x, base=10) -> integer\n",
      "\n",
      "Convert a number or string to an integer, or return 0 if no arguments\n",
      "are given.  If x is a number, return x.__int__().  For floating point\n",
      "numbers, this truncates towards zero.\n",
      "\n",
      "If x is not a number or if base is given, then x must be a string,\n",
      "bytes, or bytearray instance representing an integer literal in the\n",
      "given base.  The literal can be preceded by '+' or '-' and be surrounded\n",
      "by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\n",
      "Base 0 means to interpret the base from the string as an integer literal.\n",
      ">>> int('0b100', base=0)\n",
      "4"
     ]
    }
   ],
   "source": [
    "model.num_actions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVLA(\n",
       "  (action_space): EE6DActionSpace(\n",
       "    (mse): MSELoss()\n",
       "    (bce): BCEWithLogitsLoss()\n",
       "  )\n",
       "  (vlm): Florence2ForConditionalGeneration(\n",
       "    (vision_tower): DaViT(\n",
       "      (convs): ModuleList(\n",
       "        (0): ConvEmbed(\n",
       "          (proj): Conv2d(3, 256, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ConvEmbed(\n",
       "          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ConvEmbed(\n",
       "          (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ConvEmbed(\n",
       "          (proj): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0): MySequential(\n",
       "          (0): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.004)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.004)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): MySequential(\n",
       "          (0): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.009)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.009)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.013)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.013)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): MySequential(\n",
       "          (0): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.017)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.017)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.022)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.022)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.026)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.026)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.030)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.030)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.035)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.035)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.039)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.039)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.043)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.043)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.048)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.048)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.052)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.052)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.057)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.057)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.061)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.061)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.065)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.065)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.070)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.070)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.074)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.074)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (7): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.078)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.078)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.083)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.083)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (8): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.087)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.087)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.091)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.091)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): MySequential(\n",
       "          (0): MySequential(\n",
       "            (spatial_block): SpatialBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                )\n",
       "              )\n",
       "              (window_attn): PreNorm(\n",
       "                (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): WindowAttention(\n",
       "                  (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "                  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                  (softmax): Softmax(dim=-1)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.096)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.096)\n",
       "              )\n",
       "            )\n",
       "            (channel_block): ChannelBlock(\n",
       "              (conv1): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                )\n",
       "              )\n",
       "              (channel_attn): PreNorm(\n",
       "                (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): ChannelAttention(\n",
       "                  (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "                  (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.100)\n",
       "              )\n",
       "              (conv2): PreNorm(\n",
       "                (fn): DepthWiseConv2d(\n",
       "                  (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                )\n",
       "              )\n",
       "              (ffn): PreNorm(\n",
       "                (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "                (fn): Mlp(\n",
       "                  (net): Sequential(\n",
       "                    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): DropPath(drop_prob=0.100)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "    )\n",
       "    (image_proj_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (image_pos_embed): LearnedAbsolutePositionEmbedding2D(\n",
       "      (row_embeddings): Embedding(50, 1024)\n",
       "      (column_embeddings): Embedding(50, 1024)\n",
       "    )\n",
       "    (visual_temporal_embed): PositionalEmbeddingCosine1D()\n",
       "    (language_model): Florence2LanguageForConditionalGeneration(\n",
       "      (model): Florence2LanguageModel(\n",
       "        (shared): Embedding(51289, 1024, padding_idx=1)\n",
       "        (encoder): Florence2Encoder(\n",
       "          (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "          (embed_positions): Florence2LearnedPositionalEmbedding(4098, 1024)\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x Florence2EncoderLayer(\n",
       "              (self_attn): Florence2SdpaAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer): SoftPromptedTransformer(\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x TransformerBlock(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='tanh')\n",
       "          (drop1): Dropout(p=0.1, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (vlm_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (aux_visual_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (action_encoder): DomainAwareLinear(\n",
       "      (fc): Embedding(30, 73728)\n",
       "      (bias): Embedding(30, 1024)\n",
       "    )\n",
       "    (action_decoder): DomainAwareLinear(\n",
       "      (fc): Embedding(30, 20480)\n",
       "      (bias): Embedding(30, 20)\n",
       "    )\n",
       "    (soft_prompt_hub): Embedding(30, 32768)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfc909e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EE6DActionSpace' object has no attribute 'dim_proprio'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m action_space.gripper_idx\n\u001b[32m      3\u001b[39m action_space.dim_action\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43maction_space\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim_proprio\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/X-VLA/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'EE6DActionSpace' object has no attribute 'dim_proprio'"
     ]
    }
   ],
   "source": [
    "action_space = model.action_space\n",
    "action_space.gripper_idx\n",
    "action_space.dim_action\n",
    "action_space.dim_proprio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.domain_handler.lerobotv21 import LeRobotV21Handler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
